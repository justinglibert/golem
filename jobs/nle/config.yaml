training:
  unroll_length: 40
  batch_size: 32
  total_steps: 1_000_000_000
  entropy_cost: 0.001
  baseline_cost: 0.5
  discounting: 0.999
  learning_rate: 0.0002
  alpha: 0.99
  momentum: 0.0
  epsilon: 0.000001
  grad_norm_clipping: 40.0
env:
  task: 'NetHackScore-v0'
model:
  lstm: true
run:
  force_rank_0: learner
  tasks:
    learner:
      requirements:
        cpus: 8
        gpus: 1
      processes: 1
    actor:
      requirements:
        cpus: 4
      processes: 36 
