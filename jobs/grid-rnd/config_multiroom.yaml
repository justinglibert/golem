training:
  unroll_length: 100 # used to be 60
  batch_size: 32
  total_steps: 500_000_000 # used to be 500M
  entropy_cost: 0.0001
  baseline_cost: 0.5
  discounting: 0.99
  learning_rate: 0.0001
  alpha: 0.99
  momentum: 0.0
  epsilon: 0.01
  grad_norm_clipping: 40
  num_buffers: 16
  checkpointing_frequency: 40
  rnd_loss_coef: 0.01
    # jintrinsic_reward_coef: 0.001
  intrinsic_reward_coef: 0.005
evaluation:
  num_episodes: 20
env:
  # task: 'MiniGrid-MultiRoom-N4-S5-v0'
  # task: 'MiniGrid-MultiRoom-N6-S4-v0' # Still need more tweaking. This one is hard
  # task: 'MiniGrid-MultiRoom-N6-S4-Easy-v0'
  # task: 'MiniGrid-MultiRoom-N6-S4-v0'
  # task: 'MiniGrid-MultiRoom-N10-S4-v0'
  # task: 'MiniGrid-MultiRoom-N10-S10-v0'
  # task: 'MiniGrid-MultiRoom-N12-S10-v0'
  # task: 'MiniGrid-KeyCorridorS3R3-v0'
  task: 'MiniGrid-ObstructedMaze-2Dlh-v0'
model:
  lstm: true
  embedding_size: 256
run:
  force_rank_0: learner
  tasks:
    learner:
      requirements:
        cpus: 8
        gpus: 1
      processes: 1
    actor:
      requirements:
        cpus: 4
      processes: 92 
    evaluator:
      requirements:
        slow_gpus: 1
        cpus: 4
      processes: 1
